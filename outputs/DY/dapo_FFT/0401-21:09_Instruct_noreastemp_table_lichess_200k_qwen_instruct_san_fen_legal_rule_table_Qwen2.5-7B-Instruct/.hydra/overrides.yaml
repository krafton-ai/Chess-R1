- trainer.user_name=DY
- trainer.group_name=dapo_FFT
- trainer.experiment_name=0401-21:09_Instruct_noreastemp_table_lichess_200k_qwen_instruct_san_fen_legal_rule_table_Qwen2.5-7B-Instruct
- trainer.logger=['tensorboard']
- trainer.n_gpus_per_node=4
- trainer.nnodes=1
- trainer.save_freq=1000
- trainer.test_freq=500
- trainer.total_training_steps=1000
- trainer.resume_from_path=False
- trainer.default_local_dir=outputs/DY/dapo_FFT/0401-21:09_Instruct_noreastemp_table_lichess_200k_qwen_instruct_san_fen_legal_rule_table_Qwen2.5-7B-Instruct/checkpoint
- trainer.default_hdfs_dir=outputs/DY/dapo_FFT/0401-21:09_Instruct_noreastemp_table_lichess_200k_qwen_instruct_san_fen_legal_rule_table_Qwen2.5-7B-Instruct/checkpoint
- data.train_files=data/lichess_200k_qwen_instruct_san_fen_legal_rule_table/train.parquet
- data.val_files=data/lichess_200k_qwen_instruct_san_fen_legal_rule_table/test.parquet
- data.train_batch_size=128
- data.max_prompt_length=1024
- data.max_response_length=2048
- actor_rollout_ref.model.path=Qwen/Qwen2.5-7B-Instruct
- actor_rollout_ref.actor.optim.lr=1e-6
- actor_rollout_ref.actor.epochs=1
- actor_rollout_ref.actor.mini_batch_size=128
- actor_rollout_ref.actor.micro_batch_size_per_gpu=2
- actor_rollout_ref.actor.use_kl_loss=True
- actor_rollout_ref.actor.kl_loss_coef=0.001
- actor_rollout_ref.actor.kl_loss_type=low_var_kl
- actor_rollout_ref.actor.fsdp_config.param_offload=False
- actor_rollout_ref.actor.fsdp_config.optimizer_offload=False
- actor_rollout_ref.actor.use_token_level_loss=False
- actor_rollout_ref.rollout.name=vllm
- actor_rollout_ref.rollout.gpu_memory_utilization=0.4
- actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=8
- actor_rollout_ref.rollout.tensor_model_parallel_size=1
- actor_rollout_ref.rollout.n=8
- actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=8
- actor_rollout_ref.ref.fsdp_config.param_offload=True
- algorithm.gamma=1.0
- algorithm.discard_zero_adv_samples.enable=False
- algorithm.max_num_gen_batches=3
- algorithm.discard_maxgenlen_samples.enable=True
